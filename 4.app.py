import streamlit as st
import os

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.llms import HuggingFaceHub
from langchain.chains import RetrievalQA


# 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙØ§ØªÙŠØ­ API ÙˆÙ…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
# ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø¨Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ø§Ù„ØµØ­ÙŠØ­Ø©
os.environ["GOOGLE_API_KEY"] = "AIzaSyAWOKOFo1B79OcIjc30JIauQ_pHwsYV2pc"
os.environ["HUGGINGFACEHUB_API_TOKEN"] = "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"

# 2. ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª
PDF_FILE_PATH = r"C:\Users\Laptop World\Downloads\Documents\C++-Programming-7th-edition-by-DS-Malik.pdf"
DB_PERSIST_DIRECTORY = r"C:\Users\Laptop World\Downloads\Documents\cpp_book_db"


# 3. Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ØªÙ„Ø®ÙŠØµ ÙˆQA
# @st.cache_resource: Ù„ØªØ®Ø²ÙŠÙ† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„ØªØ¬Ù†Ø¨ Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¦Ù‡Ø§ ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©
@st.cache_resource
def setup_qa_system():
    """ØªØ¬Ù‡ÙŠØ² Ù†Ø¸Ø§Ù… QA ÙˆØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ¬Ù‡ÙŠØ©."""
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    if not os.path.exists(DB_PERSIST_DIRECTORY):
        st.info("Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ Ø§Ù„Ø¢Ù†. Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ù‡Ø°Ø§ Ø¨Ø¶Ø¹ Ø¯Ù‚Ø§Ø¦Ù‚...")
        try:
            loader = PyPDFLoader(PDF_FILE_PATH)
            documents = loader.load()
            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=500)
            chunks = text_splitter.split_documents(documents)
            
            embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
            
            db = Chroma.from_documents(
                documents=chunks,
                embedding=embeddings,
                persist_directory=DB_PERSIST_DIRECTORY,
                collection_name="cpp_book_chunks"
            )
            st.success("ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
        except FileNotFoundError:
            st.error("Ø®Ø·Ø£: Ù…Ù„Ù PDF ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.")
            return None
    else:
        st.info("ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ¬Ù‡ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­.")
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
        db = Chroma(persist_directory=DB_PERSIST_DIRECTORY, embedding_function=embeddings)
    
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆØ°Ø¬ LLM Ù„Ù„Ø±Ø¯ÙˆØ¯ (ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø®ØªÙŠØ§Ø± Ù†Ù…ÙˆØ°Ø¬ Ø¢Ø®Ø±)
    # ØªØ°ÙƒØ± Ø£Ù† Ù†Ù…Ø§Ø°Ø¬ HuggingFace ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ HuggingFace Hub API token
    llm = HuggingFaceHub(repo_id="mistralai/Mistral-7B-Instruct-v0.2")

    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø³Ù„Ø³Ù„Ø© QA (Retriever)
    qa = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=db.as_retriever()
    )
    return qa

def summarize_text(text_to_summarize):
    """ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ Ù„Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Hugging Face."""
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ù…Ø®ØµØµ Ù„Ù„ØªÙ„Ø®ÙŠØµ
    # ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¬Ø±Ø¨Ø© "facebook/bart-large-cnn" Ø£Ùˆ "google/pegasus-cnn_dailymail"
    summarizer_llm = HuggingFaceHub(repo_id="t5-small")
    prompt = f"Summarize the following text:\n\n{text_to_summarize}\n\nSummary:"
    summary = summarizer_llm(prompt)
    return summary


# 4. Ø¨Ù†Ø§Ø¡ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Streamlit
st.set_page_config(page_title="Ù…Ù„Ø®Øµ ÙˆÙ…Ø³Ø§Ø¹Ø¯ C++", layout="wide")
st.title("ğŸ‘¨â€ğŸ’» Ù…Ù„Ø®Øµ ÙˆÙ…Ø³Ø§Ø¹Ø¯ C++ Ø§Ù„Ø°ÙƒÙŠ")

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚Ø§Ø¦Ù…Ø© Ø¬Ø§Ù†Ø¨ÙŠØ© Ù„Ù„ØªÙ†Ù‚Ù„ Ø¨ÙŠÙ† Ø§Ù„ÙˆØ¸Ø§Ø¦Ù
page = st.sidebar.selectbox("Ø§Ø®ØªØ± ÙˆØ¸ÙŠÙØ©", ["ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ Ù„Ù„Ù†Øµ", "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© C++"])

if page == "ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ Ù„Ù„Ù†Øµ":
    st.header("ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ Ù„Ù„Ù†Øµ ğŸ“")
    user_input = st.text_area("Ø£Ù„ØµÙ‚ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªÙ„Ø®ÙŠØµÙ‡ Ù‡Ù†Ø§:", height=300)
    if st.button("ØªÙ„Ø®ÙŠØµ"):
        if user_input:
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙ„Ø®ÙŠØµ..."):
                summary = summarize_text(user_input)
                st.subheader("Ø§Ù„Ù…Ù„Ø®Øµ:")
                st.write(summary)
        else:
            st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ Ù„ØªÙ„Ø®ÙŠØµÙ‡.")

elif page == "Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© C++":
    st.header("Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© Ù…Ù† ÙƒØªØ§Ø¨ C++ ğŸ“š")
    qa_chain = setup_qa_system()

    if qa_chain:
        question = st.text_input("Ø§Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø¹Ù† C++:", "Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ù€ Class ÙÙŠ C++ØŸ")
        if st.button("Ø§Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©"):
            if question:
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©..."):
                    response = qa_chain.invoke(question)
                    st.subheader("Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:")
                    st.write(response["result"])
            else:
                st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø³Ø¤Ø§Ù„.")
                streamlit run 4.app.py